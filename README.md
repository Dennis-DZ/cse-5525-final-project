# Generation of Physics Simulation Specs from Natural Language

## Setup

This project uses the [uv package manager](https://docs.astral.sh/uv/). The dependencies are listed in `pyproject.toml` and can be installed with `uv sync`. Other Python package managers should also be able to install them, if needed.

## Usage

The main access-point for the project is `src/main.py`. With `uv`, run `uv run -m src.main`.

### In-Context Learning

ICL inference is run using the `icl_inference` command (i.e., `uv run -m src.main icl_inference`). By default, this will prompt `Qwen/Qwen2.5-Coder-3B-Instruct` with all of the examples in the dev dataset, using the sample prompt templates (`src/icl/sample_system_prompt.txt` and `src/icl/sample_user_prompt.txt`). The results will be saved in `output/icl_inference/data/` and a log file will be saved in `output/icl_inference/log/`. The behavior can be customized using CLI arguments. Use the `--help` option to see all of them. A few of the most useful arguments allow you to: specify different files for prompt templates, use a different model for inference, test on fewer examples, and customize where the logs and results are saved. An important note about the user prompt template is that it must contain a `%new_prompt%` placeholder, as this is where the natural language prompts are inserted for inference.

### Evaluation

The results from ICL inference can be evaluated with the `evaluate` command (i.e., `uv run -m src.main evaluate --input_path [insert_path]`). The `input_path` argument is required and must be a path to results generated by the `icl_inference` command. Evaluation results for each example are saved by default in `output/evaluation/data/`. A log file is saved in `output/evaluation/log/`, and it will contain averaged metrics across all the examples. By default, these files will have the same name as the specified input file, but this can be changed with CLI arguments.

### Fine-Tuning

Unfortunately, due to limited time, the code for fine-tuning models and evaluating them was not incorporated into the main project. Instead, `src/fine_tuning/` holds a self-contained project for doing those things. In that directory, `README_TRAINING.md` contains instructions on how to install dependencies and run the scripts.
